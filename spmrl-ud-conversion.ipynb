{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvf ./data/hebtb.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_spmrl_dev = './data/spmrl-treebank/dev_hebtb-gold.conll'\n",
    "filepath_spmrl_train = './data/spmrl-treebank/train_hebtb-gold.conll'\n",
    "filepath_spmrl_test = './data/spmrl-treebank/test_hebtb-gold.conll'\n",
    "\n",
    "filepath_ud_dev = './data/ud-treebank/he_htb-ud-dev.conllu'\n",
    "filepath_ud_train = './data/ud-treebank/he_htb-ud-train.conllu'\n",
    "filepath_ud_test = './data/ud-treebank/he_htb-ud-test.conllu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DF Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def suit_for_pandas(filepath):\n",
    "    treebank = []\n",
    "    columns = ['ID', 'FORM', 'LEMMA', 'UPOS', 'XPOS', 'FEATS', 'HEAD', 'DEPREL', 'DEPS', 'MISC']\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, sep='\\t', header=None, names=columns, na_filter=False, quoting=csv.QUOTE_NONE)\n",
    "    except:\n",
    "        with open(filepath, 'r') as source:\n",
    "            for line in source.readlines():\n",
    "                if len(line.split('\\t')) == 10:\n",
    "                    treebank.append(tuple(line.strip().split('\\t')))\n",
    "                elif len(line.split('\\t')) == 1:\n",
    "                    treebank.append((line.strip(), '', '', '', '', '', '', '', '', ''))\n",
    "            df = pd.DataFrame(data=treebank, columns=columns)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_conll_file(filepath):\n",
    "    treebank = []\n",
    "    columns = ['ID', 'FORM', 'LEMMA', 'UPOS', 'XPOS', 'FEATS', 'HEAD', 'DEPREL', 'DEPS', 'MISC']\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, sep='\\t', header=None, names=columns, na_filter=False, quoting=csv.QUOTE_NONE)\n",
    "    except:\n",
    "        with open(filepath, 'r') as source:\n",
    "            for line in source.readlines():\n",
    "                if len(line.split('\\t')) == 10:\n",
    "                    treebank.append(tuple(line.strip().split('\\t')))\n",
    "                elif len(line.split('\\t')) == 1:\n",
    "                    treebank.append((line.strip(), '', '', '', '', '', '', '', '', ''))\n",
    "            df = pd.DataFrame(data=treebank, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ud_dev = suit_for_pandas(filepath_ud_dev)\n",
    "spmrl_dev = suit_for_pandas(filepath_spmrl_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud_dev = create_df_from_conll_file(filepath_ud_dev)\n",
    "spmrl_dev = create_df_from_conll_file(filepath_spmrl_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spmrl_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud_train = suit_for_pandas(filepath_ud_train)\n",
    "spmrl_train = suit_for_pandas(filepath_spmrl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud_test = suit_for_pandas(filepath_ud_test)\n",
    "spmrl_test = suit_for_pandas(filepath_spmrl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ud_dev['sent_id'] = ''\n",
    "spmrl_dev['sent_id'] = ''\n",
    "spmrl_dev['ID'] = spmrl_dev['ID'].apply(lambda x: int(x) if str(x).isdigit() else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud_train['sent_id'] = ''\n",
    "spmrl_train['sent_id'] = ''\n",
    "spmrl_train['ID'] = spmrl_train['ID'].apply(lambda x: int(x) if str(x).isdigit() else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud_test['sent_id'] = ''\n",
    "spmrl_test['sent_id'] = ''\n",
    "spmrl_test['ID'] = spmrl_test['ID'].apply(lambda x: int(x) if str(x).isdigit() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spmrl_treebank = pd.concat([spmrl_dev, spmrl_train, spmrl_test], ignore_index=True)\n",
    "spmrl_treebank['sent_id'] = ''\n",
    "spmrl_treebank['ID'] = spmrl_treebank['ID'].apply(lambda x: int(x) if str(x).isdigit() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spmrl_train[(spmrl_train['DEPREL'] == 'posspmod') & (spmrl_train['XPOS'] != 'POS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spmrl_treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_id(df, tb):\n",
    "    if tb=='ud':\n",
    "        sent_id = 0\n",
    "        for i, row in df.iterrows():\n",
    "            if '# sent_id' in row['ID']:\n",
    "                sent_id += 1\n",
    "            else:\n",
    "                df.at[i, 'sent_id'] = sent_id\n",
    "    elif tb=='spmrl':\n",
    "        sent_id = 1\n",
    "        for i, row in df.iterrows():\n",
    "            if row['ID'] == 0:\n",
    "                df.at[i, 'sent_id'] = 0 \n",
    "            try:\n",
    "                if df.loc[i]['ID'] > df.loc[i-1]['ID']:\n",
    "                    df.at[i, 'sent_id'] = sent_id\n",
    "                elif type(df.loc[i-1]['ID']) == str:\n",
    "                    continue\n",
    "                else:\n",
    "                    sent_id += 1\n",
    "                    df.at[i, 'sent_id'] = sent_id\n",
    "            except KeyError as e:\n",
    "                df.at[i, 'sent_id'] = 1\n",
    "            except TypeError as e:\n",
    "                print(df.loc[i]['ID'],df.loc[i-1]['ID'], e)\n",
    "            except ValueError as e:\n",
    "                print(df.loc[i]['ID'] > df.loc[i-1]['ID'], e)\n",
    "                \n",
    "sentence_id(spmrl_dev, 'spmrl')\n",
    "sentence_id(ud_dev, 'ud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_id(spmrl_treebank, 'spmrl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spmrl_treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_id(spmrl_train, 'spmrl')\n",
    "sentence_id(ud_train, 'ud')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_spmrl_df = pd.DataFrame(columns=['ID', 'FORM', 'LEMMA', 'UPOS', 'XPOS', 'FEATS', 'HEAD', 'DEPREL', 'DEPS', 'MISC', 'sent_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns = {\n",
    "     'suf_gen=F|suf_gen=M|suf_num=P|suf_per=1': '_אנחנו',\n",
    "     'suf_gen=F|suf_gen=M|suf_num=S|suf_per=1': '_אני',\n",
    "     'suf_gen=M|suf_num=S|suf_per=1': '_אני', # this is a mistake in sentence 899\n",
    "     'suf_gen=M|suf_num=S|suf_per=2': '_אתה',\n",
    "     'suf_gen=F|suf_num=S|suf_per=2': '_את',\n",
    "     'suf_gen=M|suf_num=P|suf_per=2': '_אתם',\n",
    "     'suf_gen=F|suf_num=P|suf_per=2': '_אתן',\n",
    "     'suf_gen=F|suf_num=P|suf_per=3': '_הן',\n",
    "     'suf_gen=F|suf_num=S|suf_per=3': '_היא',\n",
    "     'suf_gen=M|suf_num=P|suf_per=3': '_הם',\n",
    "     'suf_gen=M|suf_num=S|suf_per=3': '_הוא',\n",
    "    'suf_gen=M|suf_num=S|per=3': '_הוא' # mistake at sentence 2348\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_segment_df(df):\n",
    "    for i, row in df.iterrows():\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_df(unsegmented_df):\n",
    "    output_df = pd.DataFrame(columns=['ID', 'FORM', 'LEMMA', 'UPOS', 'XPOS', 'FEATS', 'HEAD', 'DEPREL', 'DEPS', 'MISC', \n",
    "                                      'sent_id'])\n",
    "    for i, row in unsegmented_df.iterrows():\n",
    "        try:\n",
    "            suffix_feats = \"|\".join([x for x in row['FEATS'].split(\"|\") if 'suf' in x])\n",
    "            noun_feats = \"|\".join([x for x in row['FEATS'].split(\"|\") if 'suf' not in x])\n",
    "            clean_suffix_feats = \"|\".join([x.replace(\"suf_\", \"\") for x in row['FEATS'].split(\"|\") if 'suf' in x])\n",
    "            if 'suf_' in row['FEATS'] and row['UPOS'] == 'NN':\n",
    "        #     if row['XPOS'] == 'NN_S_PP' or row['XPOS'] == 'S_PP':\n",
    "                output_df = output_df.append({'ID': row['ID'], 'FORM': row['LEMMA'] + '_', 'LEMMA': row['LEMMA'],  \n",
    "                                              'UPOS': 'NOUN', 'XPOS': 'NOUN','FEATS': 'Definite=Def|' + noun_feats + '|xx_UD=Seg', \n",
    "                                              'HEAD': row['HEAD'], 'DEPREL': row['DEPREL'], 'DEPS': row['DEPS'], \n",
    "                                              'MISC': row['MISC'], 'sent_id': row['sent_id']}, ignore_index=True)\n",
    "\n",
    "                output_df = output_df.append({'ID': 0, 'FORM': '_של_', 'LEMMA': 'של',  'UPOS': 'ADP', \n",
    "                                              'XPOS': 'ADP','FEATS': '_'  + '|xx_UD=Seg', 'HEAD': int(row['ID']) + 2, \n",
    "                                              'DEPREL': 'case:gen', 'DEPS': row['DEPS'], 'MISC': row['MISC'],\n",
    "                                              'sent_id': row['sent_id']}, ignore_index=True)\n",
    "\n",
    "                output_df = output_df.append({'ID': 0, 'FORM': pronouns[suffix_feats], 'LEMMA': 'הוא',  'UPOS': 'PRON', \n",
    "                                              'XPOS': 'PRON','FEATS': \"Case=Gen|\" + clean_suffix_feats + \"|PronType=Prs\"+'|xx_UD=Seg, \n",
    "                                              'HEAD': int(row['ID']) + 2, 'DEPREL': 'nmod:poss', 'DEPS': row['DEPS'], \n",
    "                                              'MISC': row['MISC'],'sent_id': row['sent_id']}, ignore_index=True)\n",
    "\n",
    "            elif row['XPOS'] == 'DTT' or row['XPOS'] == 'DT':\n",
    "                if 'suf_' in row['FEATS']:\n",
    "                    output_df = output_df.append({'ID': row['ID'], 'FORM': row['FORM'], 'LEMMA': row['LEMMA'],  'UPOS': 'NOUN', \n",
    "                                                'XPOS': 'NOUN','FEATS': row['FEATS'], 'HEAD': row['HEAD'], \n",
    "                                                'DEPREL': row['DEPREL'], 'DEPS': row['DEPS'], 'MISC': row['MISC'],\n",
    "                                              'sent_id': row['sent_id']}, ignore_index=True)\n",
    "\n",
    "                    output_df = output_df.append({'ID': 0, 'FORM': \"_\" + pronouns[suffix_feats], 'LEMMA': 'הוא',  'UPOS': 'PRON',\n",
    "                                                  'XPOS': 'PRON','FEATS': \"Case=Gen|\"+clean_suffix_feats + \"|PronType=Prs\",\n",
    "                                                  'HEAD': int(row['ID']) + 1, 'DEPREL': 'nmod:poss', 'DEPS': row['DEPS'], \n",
    "                                                  'MISC': row['MISC'],'sent_id': row['sent_id']}, ignore_index=True)\n",
    "                else:\n",
    "                    output_df = output_df.append(row, ignore_index=True)            \n",
    "            else:\n",
    "                output_df = output_df.append(row, ignore_index=True)\n",
    "        except KeyError as e:\n",
    "            print(row)\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_segment_df(df, segmentations):\n",
    "    for i, row in df.iterrows():\n",
    "        suffix_feats = \"|\".join([x for x in row['FEATS'].split(\"|\") if 'suf' in x])\n",
    "        noun_feats = \"|\".join([x for x in row['FEATS'].split(\"|\") if 'suf' not in x])\n",
    "        clean_suffix_feats = \"|\".join([x.replace(\"suf_\", \"\") for x in row['FEATS'].split(\"|\") if 'suf' in x])\n",
    "        if row['XPOS'] == 'NN':\n",
    "            df.loc[i+0.5] =  ['0', 'שובל', 'שובל', 'NNP', 'NNP', 'gen=M|num=P|per=A', '10', 'obj', '_', '_', 'from file']\n",
    "    df.index = df.index + 1\n",
    "    df = df.sort_index()\n",
    "    return df\n",
    "\n",
    "\n",
    "#             suffix_feats = \"|\".join([x for x in row['FEATS'].split(\"|\") if 'suf' in x])\n",
    "#             noun_feats = \"|\".join([x for x in row['FEATS'].split(\"|\") if 'suf' not in x])\n",
    "#             clean_suffix_feats = \"|\".join([x.replace(\"suf_\", \"\") for x in row['FEATS'].split(\"|\") if 'suf' in x])\n",
    "#             if 'suf_' in row['FEATS'] and row['UPOS'] == 'NN':\n",
    "#         #     if row['XPOS'] == 'NN_S_PP' or row['XPOS'] == 'S_PP':\n",
    "#                 output_df = output_df.append({'ID': row['ID'], 'FORM': row['LEMMA'] + '_', 'LEMMA': row['LEMMA'],  \n",
    "#                                               'UPOS': 'NOUN', 'XPOS': 'NOUN','FEATS': 'Definite=Def|' + noun_feats + '|xx_UD=Seg', \n",
    "#                                               'HEAD': row['HEAD'], 'DEPREL': row['DEPREL'], 'DEPS': row['DEPS'], \n",
    "#                                               'MISC': row['MISC'], 'sent_id': row['sent_id']}, ignore_index=True)\n",
    "\n",
    "#                 output_df = output_df.append({'ID': 0, 'FORM': '_של_', 'LEMMA': 'של',  'UPOS': 'ADP', \n",
    "#                                               'XPOS': 'ADP','FEATS': '_'  + '|xx_UD=Seg', 'HEAD': int(row['ID']) + 2, \n",
    "#                                               'DEPREL': 'case:gen', 'DEPS': row['DEPS'], 'MISC': row['MISC'],\n",
    "#                                               'sent_id': row['sent_id']}, ignore_index=True)\n",
    "\n",
    "#                 output_df = output_df.append({'ID': 0, 'FORM': pronouns[suffix_feats], 'LEMMA': 'הוא',  'UPOS': 'PRON', \n",
    "#                                               'XPOS': 'PRON','FEATS': \"Case=Gen|\" + clean_suffix_feats + \"|PronType=Prs\"+'|xx_UD=Seg, \n",
    "#                                               'HEAD': int(row['ID']) + 2, 'DEPREL': 'nmod:poss', 'DEPS': row['DEPS'], \n",
    "#                                               'MISC': row['MISC'],'sent_id': row['sent_id']}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_spmrl_train = pd.DataFrame(columns=['ID', 'FORM', 'LEMMA', 'UPOS', 'XPOS', 'FEATS', 'HEAD', 'DEPREL', 'DEPS', 'MISC', 'sent_id'])\n",
    "for i, row in spmrl_train.iterrows():\n",
    "    segement_df(row, seg_spmrl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_spmrl_df = segment_df(spmrl_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_spmrl_treebank = segment_df(spmrl_treebank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_spmrl_df[seg_spmrl_df['FEATS'].str.contains('suf', na=False)]['XPOS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_spmrl_df[seg_spmrl_df['sent_id'] == 13]#['FEATS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spmrl_train[spmrl_train['sent_id'] == 3029]#['XPOS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_spmrl_df[(seg_spmrl_df['DEPREL'] == 'posspmod') & (seg_spmrl_df['XPOS'] != 'POS')]#['DEPREL'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spmrl_train[spmrl_train['FORM'].str.contains('לזרז')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_spmrl_df[seg_spmrl_df['FEATS'].str.contains('_\\|') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_previous_row(row):\n",
    "    feats = row['FEATS']\n",
    "    try:\n",
    "        prev = row.name - 1\n",
    "        prev_feats = spmrl_dev.at[prev, 'FEATS']\n",
    "        if row['XPOS'] == 'PREPOSITION':\n",
    "            spmrl_dev.at[prev, 'XPOS'] = 'ADP'\n",
    "            spmrl_dev.at[prev, 'FEATS'] = 'Case=Gen'\n",
    "            feats = prev_feats + '|PronType=Prs'\n",
    "    except:\n",
    "        return feats\n",
    "    return feats\n",
    "    \n",
    "spmrl_dev['FEATS'] = spmrl_dev.apply(change_previous_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gender\n",
    "def simple_features_conversion(column, conversions):\n",
    "    for old,new in conversions.items():\n",
    "        column = column.replace(old,new)\n",
    "\n",
    "    return column\n",
    "    \n",
    "basic_features = {'suf_': '', 'gen=F|gen=M': 'Gender=Fem,Masc', 'gen=F': 'Gender=Fem', 'gen=M':'Gender=Masc',\n",
    "               'num=S':'Number=Sing',  'num=P': 'Number=Plur',\n",
    "                'per=A': 'Person=1,2,3', 'per=': 'Person=', \n",
    "                'tense=BEINONI': 'VerbForm=Part', 'tense=TOINFINITIVE': 'VerbForm=Inf', 'tense=IMPERATIVE': 'Mood=Imp',\n",
    "                'tense=PAST': 'Tense=Past', 'tense=FUTURE': 'Tense=Fut'\n",
    "               }\n",
    "\n",
    "seg_spmrl_df.loc[:, 'FEATS']  = seg_spmrl_df['FEATS'].apply(lambda x: simple_features_conversion(x, basic_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_conversion(column, conversions):\n",
    "    if column in conversions:\n",
    "        return conversions[column]\n",
    "    else:\n",
    "        return column\n",
    "\n",
    "basic_pos = {\n",
    "         'IN': 'ADP', 'NNP': 'PROPN', 'JJ':'ADJ', 'NN': 'NOUN', 'VB': 'VERB', 'RB': 'ADV', 'NCD': 'NUM','NEG': 'ADV',\n",
    "        'PREPOSITION': 'ADP', 'REL': 'SCONJ', 'COM': 'SCONJ', 'CONJ': 'CCONJ','POS': 'ADP', 'PRP': 'PRON',\n",
    "        'yyCLN': 'PUNCT', 'yyCM': 'PUNCT', 'yyDASH': 'PUNCT', 'yyDOT': 'PUNCT', 'yyELPS': 'PUNCT', 'yyEXCL': 'PUNCT',\n",
    "        'yyLRB': 'PUNCT', 'yyQM': 'PUNCT', 'yyQUOT': 'PUNCT', 'yyRRB': 'PUNCT', 'yySCLN': 'PUNCT', 'ZVL': 'X'\n",
    "}\n",
    "seg_spmrl_df.loc[:, 'UPOS']  = seg_spmrl_df['UPOS'].apply(lambda x: pos_conversion(x, basic_pos))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_convert_entire_line(row, conversions):\n",
    "    xpos = row['XPOS']\n",
    "    form = row['FORM']\n",
    "#     if xpos in conversions:\n",
    "    if xpos in conversions:\n",
    "        if 'concat' in xpos:\n",
    "            if xpos['concat'] == 'before':\n",
    "                form = '_' + form\n",
    "            elif xpos['concat'] == 'after':\n",
    "                form += '_'\n",
    "            else:\n",
    "                form = '_' + form + '_'\n",
    "        upos = conversions[xpos]['pos']\n",
    "        if conversions[xpos]['deprel'] == 'deprel':\n",
    "            deprel = row['DEPREL']\n",
    "        else:\n",
    "            deprel = conversions[xpos]['deprel']\n",
    "        if conversions[xpos]['feats'] == 'feats':\n",
    "            feats = row['FEATS']\n",
    "        elif conversions[xpos]['feats']['old'] == '_':\n",
    "            feats = conversions[xpos]['feats']['new']\n",
    "        elif conversions[xpos]['feats']['old'] == 'feats+':\n",
    "            if len(row['FEATS']) > 2:\n",
    "                feats = row['FEATS'] + conversions[xpos]['feats']['new']\n",
    "            else:\n",
    "                feats = conversions[xpos]['feats']['new'][1:]\n",
    "        elif conversions[xpos]['feats']['old'] == '+feats':\n",
    "            feats = conversions[xpos]['feats']['new'] + row['FEATS']\n",
    "        elif conversions[xpos]['feats']['old'] == '+feats+':\n",
    "            feats = conversions[xpos]['feats']['new'][0] + row['FEATS'] + conversions[xpos]['feats']['new'][1]\n",
    "        return pd.Series([upos, deprel, feats, form])\n",
    "    else:\n",
    "        return pd.Series([row['FORM'], row['UPOS'], row['DEPREL'], row['FEATS']])\n",
    "    \n",
    "\n",
    "entire_line_pos_conversion = {\n",
    "    'AT': {'pos': 'ADP', 'deprel': 'case:acc', 'feats': {'old': '_', 'new': 'Case=Acc'}},\n",
    "    'BN': {'pos': 'VERB', 'deprel': 'deprel', 'feats': {'old': 'feats+', 'new': \"|VerbForm=Part\"}},\n",
    "    'BNT': {'pos': 'VERB', 'deprel': 'deprel', 'feats': {'old': '+feats+', 'new': ['Definite=Cons|', '|VerbForm=Part']}},\n",
    "    'CD': {'pos': 'NUM', 'deprel': 'deprel', 'feats': 'feats'},\n",
    "    'CDT': {'pos': 'NUM', 'deprel': 'deprel', 'feats': {'old': '+feats', 'new': \"Definite=Cons|\"}},\n",
    "    'NNT': {'pos': 'NOUN', 'deprel': 'deprel', 'feats': {'old': '+feats', 'new': \"Definite=Cons|\"}},\n",
    "    'COP': {'pos': 'AUX', 'deprel': 'deprel', 'feats': {'old': 'feats+', 'new': \"|VerbType=Cop|VerbForm=Part\"}},\n",
    "    'DEF': {'pos': 'DET', 'deprel': 'deprel', 'feats': {'old': '_', 'new': 'PronType=Art'}, 'concat': 'after'},\n",
    "    'EX': {'pos': 'VERB', 'deprel': 'deprel', 'feats': {'old': '_', 'new': 'HebExistential=True'}},\n",
    "    'P': {'pos': 'ADV', 'deprel': 'compound:affix', 'feats': {'old': '_', 'new': 'Prefix=True'}},\n",
    "    'DUMMY_AT': {'pos': 'ADP', 'deprel': 'case:acc', 'feats': {'old': '_', 'new': 'Case=Acc'}},\n",
    "    'JJT': {'pos': 'ADJ', 'deprel': 'deprel', 'feats': {'old': '+feats', 'new': 'Definite=Cons|'}},\n",
    "    'MD': {'pos': 'AUX', 'deprel': 'deprel', 'feats': {'old': 'feats+', 'new': '|VerbType=Mod'}},\n",
    "    'QW': {'pos': 'ADV', 'deprel': 'deprel', 'feats': {'old': '_', 'new': 'PronType=Int'}},\n",
    "    'TEMP': {'pos': 'SCONJ', 'deprel': 'mark', 'feats': {'old': '_', 'new': 'Case=Tem'}},\n",
    "    'DTT': {'pos': 'DET', 'deprel': 'deprel', 'feats': {'old': '_', 'new': 'Definite=Cons'}},\n",
    "    'S_ANP': {'pos': 'PRON', 'deprel': 'deprel', 'feats': {'old': '+feats+', 'new': ['Case=Acc|', '|PronType=Prs']}} \n",
    "    'S_PRP': {'pos': 'PRON', 'deprel': 'deprel', 'feats': {'old': 'feats+', 'new': '|PronType=Prs|Reflex=Yes'}}\n",
    "}\n",
    "\n",
    "seg_spmrl_df[['FORM', 'UPOS', 'DEPREL', 'FEATS']] = seg_spmrl_df.apply(lambda x: pos_convert_entire_line(x, entire_line_pos_conversion), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missing:\n",
    "ADVERB - lexical?\n",
    "CC - lexical decision?\n",
    "DT/DTT - Already handled in segmentation\n",
    "NN_S_PP -  Already handled in segmentation\n",
    "S_PP - Already handled in segmentation\n",
    "S_PRP - Already handled in segmentation\n",
    "S_PRN - Already handled in segmentation\n",
    "DEf - typo in spmrl tb\n",
    "INTJ - doesn't change\n",
    "\n",
    "NEG\n",
    "S_ANP - Case=Acc|Gender=Masc|Number=Plur|Person=3|PronType=Prs\n",
    "\n",
    "\n",
    "POS - interaction DEPREL/POS\n",
    "PRP - interaction DEPREL/POS\n",
    "\n",
    "==========================================\n",
    "changed:\n",
    "AT, BN, BNT, CD, CDT, NNT, COP, DEF, EX, P, DUMMY_AT, JJT. MD. QW. TEMP\n",
    "'IN', 'NNP', 'JJ', 'NN', 'VB'\n",
    "'PREPOSITION', 'REL', 'COM', 'CONJ','POS', 'PRP'\n",
    "'yyCLN', 'yyCM': 'yyDASH' 'yyDOT' 'yyELPS', 'yyEXCL', 'yyLRB', 'yyQM' 'ZVL'\n",
    "\n",
    "===========================================\n",
    "\n",
    "'CDT', 'NN', 'BN', 'PREPOSITION', 'NNP', 'TEMP', 'PRP', 'yyCM',\n",
    "       'CC', 'RB', 'JJ', 'yyDOT', 'VB', 'NNT', 'DEF', 'CONJ', 'POS',\n",
    "       'REL', 'yyLRB', 'yyRRB', 'yyQUOT', 'AT', 'NN_S_PP', 'CD', 'IN',\n",
    "       'QW', 'S_PRN', 'BNT', 'P', 'yyDASH', 'MD', 'DTT', 'COP', 'JJT',\n",
    "       'yyCLN', 'yySCLN', 'yyQM', 'yyEXCL', 'EX', 'yyELPS', 'DUMMY_AT',\n",
    "       'ADVERB', '', 'INTJ', 'ZVL', 'S_PRP', 'NEG', 'NCD', 'DEf', 'S_ANP',\n",
    "       'S_PP',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missing in conversion of form:\n",
    "1. when the article is silent (e.g. l+h+memshala), the h needs to be prefixed by _ (though I'm not sure why not _h_ and also why the l isn't suffixed).\n",
    "2. spaceAfter needs to be added. Record logic\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
